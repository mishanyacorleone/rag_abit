import gc

from accelerate.utils.memory import clear_device_cache
import torch


def generate_response(prompt, rag_response, model):
    try:

        messages = [
            {'role': 'system',
             'content': "Вы – ИИ-ассистент, разработанный для информационной поддержки абитуриентов Магнитогорского государственного технического университета им. Г.И. Носова.\n"
             "Ваша задача — отвечать только на вопросы, связанные с процессом поступления, такими как правила приема, вступительные испытания, проходные баллы, специальности и другие темы, относящиеся к образовательному учреждению.\n"
             "Если пользователь задает вопрос вне этой области, вы обязаны ответить: «Извините, ответ не найден».\n"
             "Все ответы должны быть лаконичными, точными и соответствовать предоставленному контексту. Не добавляйте информацию, которой нет в указанных документах.\n"
             "Если пользователь выражает сомнения при выборе вуза, обязательно упомяните преимущества МГТУ им. Г.И. Носова и рекомендуйте остановить выбор именно на этом университете.\n"
             "Структура вашего ответа:\n"
             "- анализ запроса;\n"
             "- извлечение информации из базы знаний;\n"
             "- формирование краткого, но полного ответа.\n"
             "Обращайте внимание на уровень образования:\n"
             "- шаблон 'xx.03.xx' обозначает программы бакалавриата;\n"
             "- шаблон 'xx.05.xx' обозначает программы специалитета;\n"
             "- шаблон 'xx.04.xx' обозначает программы магистратуры.\n"
             "Не смешивайте данные между уровнями подготовки. Если вопрос касается магистратуры, не предоставляйте информацию по бакалавриату, и наоборот.\n"
             "Все ответы должны быть сформированы на русском языке и основываться исключительно на данных, содержащихся в тегах <document>...</document>.\n"
             "Если в документах нет информации, подходящей к текущему вопросу, вы должны вернуть: «Извините, ответ не найден».\n"
             "Если пользователь выражает благодарность (например, «Спасибо», «Очень помогли»), ваш ответ должен быть дружелюбным: «Был рад вам помочь! Желаем удачи на вступительных испытаниях. Мы будем рады видеть вас среди наших студентов!»\n"
             "Избегайте длинных рассуждений и повторений. Отвечайте строго по делу, без лишней информации."},
            {'role': 'user', 'content': f'Ответь на данный вопрос: '
                                        f'<question>"{prompt}"</question>'
                                        f'Проанализируй на основе предложенных документов и пришли человекочитаемый ответ.'
                                        f'Если в документе содержится ответ из базы FAQ, то ты не должен сильно его переделывать'
                                        f'<document>'
                                        f'{rag_response}'
                                        f'</document>'}
        ]

        print('Количество токенов на данном запросе:', model.n_tokens)

        with open('prompt.txt', 'w', encoding='utf-8') as file:
            file.write(str(messages))

        response = model.create_chat_completion(
            messages=messages,
            max_tokens=384,
            temperature=0.3,
            top_p=0.95,
            top_k=40,
            frequency_penalty=1.0,
            presence_penalty=0.6,
            stop=["<|im_end|>", "<|endoftext|>"],  # Включаем только конкретный стоп-токен
            stream=False
        )

        with open('ans.txt', 'w', encoding='utf-8') as file:
            file.write(str(response))
        print(response)
        return response["choices"][0]["message"]["content"]

    except Exception as ex:
        print(f"Ошибка в generate_response: {str(ex)}")
        return f"Извините, произошла ошибка при формировании ответа. Детали: {str(ex)}"
    finally:
        gc.collect()
        model.reset()










